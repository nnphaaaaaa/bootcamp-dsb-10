# -*- coding: utf-8 -*-
"""proj_analyzed sales(mini project).py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M1u4NRAryNIgQm90hjpvpl9P1j8hi9Xa

# Project analyzed sales (mini project)

- Analyzing Sales Data  

Author: Naphaphon Phayakkapes
"""

# import data
import numpy as np
import pandas as pd
df = pd.read_csv("sample-store.csv")

# preview top 5 rows
df.head()

# shape of dataframe
df.shape

# see data frame information using .info()
df.info()

"""We can use `pd.to_datetime()` function to convert columns 'Order Date' and 'Ship Date' to datetime.

"""

# example of pd.to_datetime() function
pd.to_datetime(df['Order Date'].head(), format='%m/%d/%Y')
pd.to_datetime(df['Ship Date'].head(), format='%m/%d/%Y')

# TODO - convert order date and ship date to datetime in the original dataframe
df['Order Date']  = pd.to_datetime(df['Order Date'], format = '%m/%d/%Y')
df['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%m/%d/%Y')
df

# TODO - count nan in postal code column
count_nan = df['Postal Code'].isna().sum()
print(f"Number of missing values in 'Postal Code' column: {count_nan}")

# TODO - filter rows with missing values
df_filter = df.dropna()
df_filter

# TODO - Explore this dataset on your owns, ask your own questions
    # how many order each city and segment
df_filter.groupby(['City', 'Segment']).size().reset_index(name = 'count')

"""## Data Analysis Part
Answer 10 below questions to get credit from this course. Write pandas code to find answers.
"""

# TODO 01 - how many columns, rows in this dataset
df.shape

#TODO 02 - is there any missing values?, if there is, which colunm? how many nan values?
df.info()
# Postal Code - missing 11 values

# TODO 03 - your friend ask for `California` data, filter it and export csv for him
df_california = df[df['State'] == 'California']
df_california.to_csv('california_data.csv')

# TODO 04 - your friend ask for all order data in `California` and `Texas` in 2017 (look at Order Date), send him csv file

    # Filter order data for California and Texas in 2017
CA_TX_DF = df[
    (df['State'].isin(['California', 'Texas'])) &
    (df['Order Date'] >= pd.Timestamp('2017-01-01')) &
    (df['Order Date'] <= pd.Timestamp('2017-12-31'))
].dropna()

    # Export the filtered result to a CSV file
CA_TX_DF.to_csv("ca_tx_all_order_2017.csv")

# TODO 05 - how much total sales, average sales, and standard deviation of sales your company make in 2017

    # filter data for 1027
sales_2017 = df[
                (df ['Order Date'] >= pd.Timestamp('2017-01-01')) &
                (df ['Order Date'] <= pd.Timestamp('2017-12-31'))
].dropna()

    #calculate total, averaage and standard devition of sales
import numpy as np
print (f"Total sales in 2017: {np.sum(sales_2017['Sales']):.2f}")
print (f"Average sales in 2017: {np.mean(sales_2017['Sales']):.2f}")
print (f"Standard deviation of sales in 2017: {np.std(sales_2017['Sales']):.2f}")

# TODO 06 - which Segment has the highest profit in 2018

    #filter data for 2018
data_2018 = df[
    (df['Order Date'] >= pd.Timestamp('2018-01-01') )  &
    (df['Order Date'] <= pd.Timestamp('2018-12-31') )
].dropna()

    #group by Segment and calculate total profit
segment_profit = data_2018.groupby('Segment')['Profit'].sum()

    #find the segment with highest profit
highest_profit_segmant = segment_profit.idxmax()
highest_profit_value = segment_profit.max()

print(f"The segment with the highest profit in 2018 is ' {highest_profit_segmant} with a profit of {highest_profit_value:.2f}")

# TODO 07 - which top 5 States have the least total sales between 15 April 2019 - 31 December 2019

    #filter data between 15 April 2019 - 31 December 2019
filter_date  = df[
    (df['Order Date'] >= pd.Timestamp('2019-04-15')) &
    (df['Order Date'] <= pd.Timestamp('2019-12-31'))
].dropna()

    # Group  by 'State ' and calculate to total sales
state_sales = filter_date.groupby('State')['Sales'].sum()

    # Sort the states by total sales in ascending order
least_sales_states = state_sales.sort_values(ascending=True).head()

print( f"Top 5 States with the least total sales between 15 April 2019 - 31 December 2019 : {least_sales_states}")

# TODO 08 - what is the proportion of total sales (%) in West + Central in 2019 e.g. 25%

    #  filter data in 2019
sales_2019 = df[
    (df['Order Date'] >= pd.Timestamp('2019-01-01')) &
    (df['Order Date'] <= pd.Timestamp('2019-12-31'))
].dropna()

    # calculate  total overall in 2019
total_sales = np.sum(sales_2019['Sales'])


    # filter for 'west' and 'central in 2019'
df_west_central = sales_2019[
    (sales_2019['Region'] == 'West') |
    (sales_2019['Region'] == 'Central')
].dropna()

    # calculate total sales  for 'West' and 'Central'
df_west_central_sales = np.sum(df_west_central['Sales'])


    #  calculate the proportion of sales and print  it
proportion = round((df_west_central_sales /  total_sales) *100, 2)

print(f"The proportion of total sales in West + Central in 2019 is {proportion}%.")

# TODO 09 - find top 10 popular products in terms of number of orders
#           vs. total sales during 2019-2020

    #filter dataset for year in 2019-2020
filter_2019_2020 = df[
    (df['Order Date'] >= pd.Timestamp('2019-01-01') ) &
    (df['Order Date'] <= pd.Timestamp('2020-12-31') )
].dropna()

    #  group by 'Product Name' and calculte total sales and number of orders
result = filter_2019_2020.groupby('Product Name').\
         agg(total_sales = ('Sales', 'sum'),number_of_order = ('Order ID', 'count'))

    # sort the result  by total  sales in descending orders
result_sorted_by_sales = result.sort_values(by='total_sales', ascending=False)

    #sort the resu lts  b y number_of_order in  descending  order
result_sorted_by_order = result.sort_values(by = 'number_of_order', ascending = False  )


    #display the top 10 popular products
print("Top 10 popular products in terms of number of sales:")
print(result_sorted_by_sales.head(10))

print("\nTop 10 popular products in terms of total orders :")
print(result_sorted_by_order.head(10))

# TODO 10 - plot at least 2 plots, any plot you think interesting :)

## ---------- 1st plot ---------- ##

import seaborn as sns
import matplotlib.pyplot as plt

# Create a boxplot for Sales across different Segments
plt.figure(figsize=(8, 6))
sns.boxplot(x='Segment', y='Sales', data=df)
plt.title("Boxplot of Sales by Segment")
plt.xlabel("Segment")
plt.ylabel("Sales")
plt.show()

## ---------- 2nd plot ---------- ##

df_clean =  df.dropna().copy()

  #check 'Order date' is a datetime format. If not, convert it back to datetime format .
if df_clean['Order Date'].dtype != np.dtype('datetime64[ns]'):
    df_clean['Order Date'] = pd.to_datetime(df_clean['Order Date'], format='%m/%d/%Y')

  # create a new column for year and month
df_clean['YearMonth'] = df_clean['Order Date'].dt.to_period('M')

  #group by the new 'YearMonth' column and sum sales
df_sales_month = df_clean.groupby('YearMonth')['Sales'].sum().reset_index()

  #convert 'YearMonth' back to datetime for plotting
df_sales_month['YearMonth'] = df_sales_month['YearMonth'].dt.to_timestamp()

  #create the line plot
plt.figure(figsize=(12, 6))
plt.plot(df_sales_month['YearMonth'], df_sales_month['Sales'])
plt.xlabel('Date')
plt.ylabel('Sales')
plt.title('Total Sales Over Time')
plt.show()

## ---------- 3rd plot ---------- ##


df_clean = df.copy().dropna()
# check 'Order Date' is in datetime format. If not, convert it back to datetime format.
if df_clean['Order Date'].dtype != np.dtype('datetime64[ns]'):
    df_clean['Order Date'] = pd.to_datetime(df_clean['Order Date'], format='%m/%d/%Y')


# create a new column for year and month
df_clean['YearMonth'] = df_clean['Order Date'].dt.to_period('M')
df_clean['Year'] = df_clean['Order Date'].dt.year
df_clean['Month'] = df_clean['Order Date'].dt.month

# group by the new 'YearMonth' column and sum sales
df_sale_month = df_clean.groupby([ 'Year', 'Month' ]).agg({'Sales': 'sum'}).reset_index()
df_sale_month['YearMonth'] = df_sale_month[ 'Year' ].astype(str) + "-" + df_sale_month[ 'Month' ].astype(str)

# create the line plot
plt.figure(figsize=(10, 6))
for year in df_clean['Year'].unique():
    year_data = df_sale_month[df_sale_month['Year'] == year]
    plt.plot(year_data['Month'], year_data['Sales'], label=year)

plt.xlabel('Month')
plt.ylabel('Sales')
plt.title('Year Sales by Month')
plt.legend()
plt.show()